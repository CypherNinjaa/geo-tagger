<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Smart Attendance System</title>
  <script src="https://cdn.jsdelivr.net/npm/@tailwindcss/browser@4"></script>
  <script src="./face-api.min.js"></script>
</head>

<body class="bg-neutral-100 min-h-svh md:pt-10">
  <div class="container bg-white max-w-[500px] mx-auto">
    <div class="px-5 pt-5 md:pt-6">
      <div class="flex">
        <p class="text-[10px] text-neutral-500 ml-auto tracking-[2px]">EDUCATIONAL PURPOSES</p>
      </div>
      <div class="flex items-center mt-1">
        <svg xmlns="http://www.w3.org/2000/svg" class="h-8" viewBox="0 0 24 24">
          function drawRegistrati function drawAttendanceResult(record, lat, lon, timestamp, ipText, accuracy) {
          const texts = [
          record.success ? "‚úÖ ATTENDANCE MARKED" : "‚ùå ATTENDANCE FAILED",
          `ü§ñ Detector: ${currentFaceDetector.toUpperCase()}`,
          `üëÅÔ∏è Liveness: VERIFIED (${blinkCount} blinks, EAR: ${EAR_THRESHOLD})`,
          `üë§ Face Match: ${record.faceMatch ? 'YES' : 'NO'} (${(1 - record.faceDistance) * 100}%)`,
          `üìç Location Match: ${record.locationMatch ? 'YES' : 'NO'} (${record.locationDistance}m)`,
          `üìç Current: ${lat.toFixed(6)}, ${lon.toFixed(6)}`,
          `üïê Time: ${timestamp.toLocaleString()}`,
          `üíª ${ipText}`
          ];

          const bgColor = record.success ? "rgba(0,128,0,0.8)" : "rgba(220,38,38,0.8)";
          drawInfoOnCanvas(texts, bgColor);
          }n, timestamp, ipText, accuracy) {
          const texts = [
          "üéØ USER REGISTERED",
          `ü§ñ Detector: ${currentFaceDetector.toUpperCase()}`,
          `üëÅÔ∏è Liveness: VERIFIED (${blinkCount} blinks, EAR: ${EAR_THRESHOLD})`,
          `üìç Location: ${lat.toFixed(6)}, ${lon.toFixed(6)}`,
          `üìç Accuracy: ¬±${accuracy}m`,
          `üïê Time: ${timestamp.toLocaleString()}`,
          `üíª ${ipText}`,
          "‚úÖ Ready for attendance verification"
          ];

          drawInfoOnCanvas(texts, "rgba(0,128,0,0.8)");
          }ill="currentColor"
          d="M12.275 9H19.4q-.675-1.725-2.062-2.963T14.15 4.3l-2.3 3.95q-.15.25 0 .5t.425.25m-3.6
          1.25q.15.25.425.25t.425-.25L13.1 4.1q-.275-.05-.55-.075T12 4q-1.65 0-3.075.625T6.4 6.3zM4.25 14h4.575q.275 0
          .438-.25t.012-.5L5.7 7.1q-.8 1.025-1.25 2.263T4 12q0 .525.063 1.013T4.25 14m5.6
          5.7l2.275-3.95q.15-.25-.012-.5t-.438-.25H4.6q.675 1.725 2.063 2.963T9.85 19.7M12 20q1.65 0 3.075-.625T17.6
          17.7l-2.275-3.95q-.15-.25-.425-.25t-.425.25L10.9 19.9q.275.05.538.075T12 20m6.3-3.1q.8-1.025 1.25-2.262T20
          12q0-.525-.062-1.012T19.75 10h-4.575q-.275 0-.437.25t-.013.5zM12 22q-2.05
          0-3.875-.788t-3.187-2.15t-2.15-3.187T2 12q0-2.075.788-3.887t2.15-3.175t3.187-2.15T12 2q2.075 0 3.888.788t3.174
          2.15t2.15 3.175T22 12q0 2.05-.788 3.875t-2.15 3.188t-3.175 2.15T12 22" />
        </svg>
        <h1 class="font-semibold text-xl text-neutral-800 ml-2">Smart Attendance</h1>
      </div>
    </div>
    <div class="px-5 mt-3">
      <p class="text-neutral-600 text-sm leading-6">
        An intelligent attendance system that uses facial recognition and GPS location verification.
        Register your face on first capture, then check attendance with automatic face and location matching.
      </p>
    </div>
    <div class="mt-5">
      <video id="video" autoplay playsinline></video>
      <canvas id="canvas" class="max-w-[500px] block w-full" style="display: none"></canvas>
    </div>
    <div class="p-4 items-center justify-center gap-4">
      <button id="captureBtn" class="bg-neutral-800 text-sm text-white py-2 px-5 w-fit rounded-lg">Mark
        Attendance</button>
      <button id="switchBtn" class="bg-neutral-200 text-sm py-2 px-5 w-fit rounded-lg">Switch camera</button>
      <button id="downloadBtn" class="bg-neutral-800 text-sm text-white py-2 px-5 w-fit rounded-lg"
        style="display: none">Download Photo</button>
      <button id="reCapture" class="bg-neutral-200 text-sm py-2 px-5 w-fit rounded-lg"
        style="display: none">Recapture</button>
      <button id="resetData" class="bg-red-600 text-sm text-white py-2 px-5 w-fit rounded-lg">Reset Data</button>
      <div id="locationStatus" class="text-xs text-neutral-500 mt-2" style="display: none">üåç Getting location...</div>
      <div id="attendanceStatus" class="text-xs mt-2" style="display: none"></div>
    </div>
    <div class="p-5 flex flex-wrap gap-4 items-center">
      <a href="https://github.com/priyangsubanerjee/geo-tagger" class="flex items-center gap-2 text-sm">
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24">
          <path fill="currentColor"
            d="M12 2A10 10 0 0 0 2 12c0 4.42 2.87 8.17 6.84 9.5c.5.08.66-.23.66-.5v-1.69c-2.77.6-3.36-1.34-3.36-1.34c-.46-1.16-1.11-1.47-1.11-1.47c-.91-.62.07-.6.07-.6c1 .07 1.53 1.03 1.53 1.03c.87 1.52 2.34 1.07 2.91.83c.09-.65.35-1.09.63-1.34c-2.22-.25-4.55-1.11-4.55-4.92c0-1.11.38-2 1.03-2.71c-.1-.25-.45-1.29.1-2.64c0 0 .84-.27 2.75 1.02c.79-.22 1.65-.33 2.5-.33s1.71.11 2.5.33c1.91-1.29 2.75-1.02 2.75-1.02c.55 1.35.2 2.39.1 2.64c.65.71 1.03 1.6 1.03 2.71c0 3.82-2.34 4.66-4.57 4.91c.36.31.69.92.69 1.85V21c0 .27.16.59.67.5C19.14 20.16 22 16.42 22 12A10 10 0 0 0 12 2" />
        </svg>
        <span>Source code</span>
      </a>
      <a href="https://priyangsu.dev/" class="flex items-center gap-0 text-sm ml-auto">
        <span class="text-neutral-500">project by</span>
        <span class="flex items-center border-b border-dashed border-neutral-300 ml-3">
          <img src="./assets/priyangsu-avatar.jpg" class="h-10 -ml-2" />
          <span class="-ml-1">Vikash </span>
        </span>
      </a>
    </div>
  </div>

  <script>
    const video = document.getElementById("video");
    const canvas = document.getElementById("canvas");
    const captureBtn = document.getElementById("captureBtn");
    const downloadBtn = document.getElementById("downloadBtn");
    const reCaptureBtn = document.getElementById("reCapture");
    const switchBtn = document.getElementById("switchBtn");
    const resetDataBtn = document.getElementById("resetData");
    const locationStatus = document.getElementById("locationStatus");
    const attendanceStatus = document.getElementById("attendanceStatus");
    const ctx = canvas.getContext("2d");

    let currentStream = null;
    let currentDeviceId = null;
    let videoDevices = [];
    let deviceIndex = 0;
    let count = 2;
    let isModelsLoaded = false;
    let isRegistered = false;

    // Face-api.js configuration
    const MODEL_URL = './weights';
    const FACE_MATCH_THRESHOLD = 0.6; // Lower means stricter matching
    const LOCATION_MATCH_THRESHOLD = 100; // meters

    // Eye blink detection configuration
    const EAR_THRESHOLD = 0.3; // Eye Aspect Ratio threshold for blink detection (tested value)
    const CONSECUTIVE_FRAMES = 3; // Number of consecutive frames below threshold to register a blink
    const REQUIRED_BLINKS = 2; // Number of blinks required for liveness verification
    let blinkCount = 0;
    let consecutiveFrames = 0;
    let earHistory = [];
    let isLivenessCheckActive = false;
    let livenessCheckTimeout = null;

    // Face detector configuration
    let currentFaceDetector = 'ssd'; // 'ssd' or 'tiny'
    let detectionRetryCount = 0;
    const MAX_RETRY_ATTEMPTS = 2;

    // Load face-api.js models
    async function loadModels() {
      try {
        locationStatus.style.display = "block";
        locationStatus.textContent = "üì• Loading AI models...";

        // Load both face detectors for fallback capability
        await faceapi.nets.ssdMobilenetv1.loadFromUri(MODEL_URL);
        await faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL);
        await faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL);
        await faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL);

        isModelsLoaded = true;
        locationStatus.style.display = "none";

        // Check if user is already registered
        const registeredData = localStorage.getItem('attendanceRegistration');
        if (registeredData) {
          isRegistered = true;
          captureBtn.textContent = "Mark Attendance";
          showAttendanceStatus("‚úÖ User registered. Ready for attendance!", "text-green-600");
        } else {
          captureBtn.textContent = "Register Face";
          showAttendanceStatus("üìù Please register your face first", "text-blue-600");
        }
      } catch (error) {
        console.error('Error loading models:', error);
        showAttendanceStatus("‚ùå Error loading AI models", "text-red-600");
      }
    }

    function showAttendanceStatus(message, className) {
      attendanceStatus.style.display = "block";
      attendanceStatus.textContent = message;
      attendanceStatus.className = `text-xs mt-2 ${className}`;
    }

    // Get face detector options based on current detector
    function getFaceDetectorOptions() {
      if (currentFaceDetector === 'ssd') {
        return new faceapi.SsdMobilenetv1Options({
          minConfidence: 0.5,
          maxResults: 1
        });
      } else {
        return new faceapi.TinyFaceDetectorOptions({
          inputSize: 416,
          scoreThreshold: 0.5
        });
      }
    }

    // Switch to fallback detector
    function switchToFallbackDetector() {
      if (currentFaceDetector === 'ssd') {
        currentFaceDetector = 'tiny';
        showAttendanceStatus("üîÑ Switching to Tiny Face Detector for better detection...", "text-blue-600");
        return true;
      }
      return false; // No more fallbacks available
    }

    // Detect face with fallback capability
    async function detectFaceWithFallback(inputElement) {
      let detection = null;
      let attempts = 0;

      while (attempts <= MAX_RETRY_ATTEMPTS && !detection) {
        try {
          const options = getFaceDetectorOptions();

          if (currentFaceDetector === 'ssd') {
            detection = await faceapi
              .detectSingleFace(inputElement, options)
              .withFaceLandmarks()
              .withFaceDescriptor();
          } else {
            detection = await faceapi
              .detectSingleFace(inputElement, options)
              .withFaceLandmarks()
              .withFaceDescriptor();
          }

          if (!detection && attempts < MAX_RETRY_ATTEMPTS) {
            attempts++;
            if (switchToFallbackDetector()) {
              locationStatus.textContent = `üîÑ Retrying with ${currentFaceDetector.toUpperCase()} detector (${attempts + 1}/${MAX_RETRY_ATTEMPTS + 1})...`;
              await new Promise(resolve => setTimeout(resolve, 500)); // Brief pause before retry
            } else {
              break;
            }
          } else {
            break;
          }
        } catch (error) {
          console.error(`Face detection error with ${currentFaceDetector}:`, error);
          attempts++;
          if (attempts <= MAX_RETRY_ATTEMPTS && switchToFallbackDetector()) {
            locationStatus.textContent = `üîÑ Retrying with ${currentFaceDetector.toUpperCase()} detector (${attempts + 1}/${MAX_RETRY_ATTEMPTS + 1})...`;
            await new Promise(resolve => setTimeout(resolve, 500));
          } else {
            break;
          }
        }
      }

      if (detection) {
        showAttendanceStatus(`‚úÖ Face detected using ${currentFaceDetector.toUpperCase()} detector`, "text-green-600");
      }

      return detection;
    }

    // Calculate Eye Aspect Ratio (EAR) for blink detection
    function calculateEAR(eyeLandmarks) {
      // eyeLandmarks should be an array of 6 points for one eye
      // Points are in order: [outer_corner, top_left, top_right, inner_corner, bottom_right, bottom_left]

      // Vertical distances
      const verticalDist1 = Math.sqrt(
        Math.pow(eyeLandmarks[1].x - eyeLandmarks[5].x, 2) +
        Math.pow(eyeLandmarks[1].y - eyeLandmarks[5].y, 2)
      );
      const verticalDist2 = Math.sqrt(
        Math.pow(eyeLandmarks[2].x - eyeLandmarks[4].x, 2) +
        Math.pow(eyeLandmarks[2].y - eyeLandmarks[4].y, 2)
      );

      // Horizontal distance
      const horizontalDist = Math.sqrt(
        Math.pow(eyeLandmarks[0].x - eyeLandmarks[3].x, 2) +
        Math.pow(eyeLandmarks[0].y - eyeLandmarks[3].y, 2)
      );

      // Calculate EAR
      const ear = (verticalDist1 + verticalDist2) / (2.0 * horizontalDist);
      return ear;
    }

    // Detect blink based on EAR
    function detectBlink(landmarks) {
      const leftEye = landmarks.getLeftEye();
      const rightEye = landmarks.getRightEye();

      const leftEAR = calculateEAR(leftEye);
      const rightEAR = calculateEAR(rightEye);
      const avgEAR = (leftEAR + rightEAR) / 2.0;

      // Store EAR history for smoothing
      earHistory.push(avgEAR);
      if (earHistory.length > 10) {
        earHistory.shift();
      }

      // Check if EAR is below threshold
      if (avgEAR < EAR_THRESHOLD) {
        consecutiveFrames++;
      } else {
        // If we had enough consecutive frames, count it as a blink
        if (consecutiveFrames >= CONSECUTIVE_FRAMES) {
          blinkCount++;
          console.log(`Blink detected! Count: ${blinkCount}`);

          if (isLivenessCheckActive) {
            showAttendanceStatus(`üëÅÔ∏è Blink ${blinkCount}/${REQUIRED_BLINKS} detected`, "text-blue-600");
          }
        }
        consecutiveFrames = 0;
      }

      return {
        avgEAR: avgEAR,
        blinkCount: blinkCount,
        isBlinking: consecutiveFrames >= CONSECUTIVE_FRAMES
      };
    }

    // Start liveness check
    function startLivenessCheck() {
      blinkCount = 0;
      consecutiveFrames = 0;
      earHistory = [];
      isLivenessCheckActive = true;

      showAttendanceStatus(`üëÅÔ∏è Please blink ${REQUIRED_BLINKS} times slowly`, "text-blue-600");

      // Set timeout for liveness check (15 seconds)
      livenessCheckTimeout = setTimeout(() => {
        if (blinkCount < REQUIRED_BLINKS) {
          isLivenessCheckActive = false;
          captureBtn.textContent = isRegistered ? "Mark Attendance" : "Register Face";
          captureBtn.disabled = false;
          locationStatus.style.display = "none";
          showAttendanceStatus("‚ùå Liveness check failed. Please try again.", "text-red-600");
        }
      }, 15000);
    }

    // Check if liveness verification is complete
    function checkLivenessComplete() {
      if (isLivenessCheckActive && blinkCount >= REQUIRED_BLINKS) {
        isLivenessCheckActive = false;
        clearTimeout(livenessCheckTimeout);
        showAttendanceStatus("‚úÖ Liveness verified! Processing...", "text-green-600");
        return true;
      }
      return false;
    }

    // Calculate distance between two GPS coordinates (Haversine formula)
    function calculateDistance(lat1, lon1, lat2, lon2) {
      const R = 6371e3; // Earth's radius in meters
      const œÜ1 = lat1 * Math.PI / 180;
      const œÜ2 = lat2 * Math.PI / 180;
      const ŒîœÜ = (lat2 - lat1) * Math.PI / 180;
      const ŒîŒª = (lon2 - lon1) * Math.PI / 180;

      const a = Math.sin(ŒîœÜ / 2) * Math.sin(ŒîœÜ / 2) +
        Math.cos(œÜ1) * Math.cos(œÜ2) *
        Math.sin(ŒîŒª / 2) * Math.sin(ŒîŒª / 2);
      const c = 2 * Math.atan2(Math.sqrt(a), Math.sqrt(1 - a));

      return R * c; // Distance in meters
    }

    // Get local IP using WebRTC as fallback
    async function getLocalIP() {
      return new Promise((resolve) => {
        try {
          const pc = new RTCPeerConnection({
            iceServers: [{ urls: "stun:stun.l.google.com:19302" }]
          });

          pc.createDataChannel("");
          pc.createOffer()
            .then(offer => pc.setLocalDescription(offer))
            .catch(() => resolve(null));

          pc.onicecandidate = (ice) => {
            if (!ice || !ice.candidate || !ice.candidate.candidate) return;
            const match = /([0-9]{1,3}(\.[0-9]{1,3}){3})/.exec(ice.candidate.candidate);
            if (match) {
              pc.close();
              resolve(match[1]);
            }
          };

          // Timeout after 3 seconds
          setTimeout(() => {
            pc.close();
            resolve(null);
          }, 3000);
        } catch (error) {
          resolve(null);
        }
      });
    }

    // Access the camera
    async function startCamera(deviceId = null) {
      if (currentStream) {
        currentStream.getTracks().forEach((track) => track.stop());
      }

      const isIOS = /iPhone|iPad|iPod/i.test(navigator.userAgent);

      const constraints = isIOS
        ? {
          video: {
            facingMode: count % 2 === 0 ? "environment" : "user",
          },
          audio: false,
        }
        : {
          video: deviceId ? { deviceId: { exact: deviceId } } : true,
          audio: false,
        };

      try {
        const stream = await navigator.mediaDevices.getUserMedia(constraints);
        currentStream = stream;
        video.srcObject = stream;
        video.play();
      } catch (err) {
        console.error("Camera error:", err);
      }
    }

    function stopCamera() {
      if (video.srcObject) {
        video.srcObject.getTracks().forEach((track) => track.stop());
        video.srcObject = null;
        switchBtn.style.display = "none";
      }
    }

    async function getVideoDevices() {
      const devices = await navigator.mediaDevices.enumerateDevices();
      console.log("Devices:", devices);
      videoDevices = devices.filter((d) => d.kind === "videoinput");
    }

    switchBtn.addEventListener("click", async () => {
      if (videoDevices.length <= 1) {
        const isIOS = /iPhone|iPad|iPod/i.test(navigator.userAgent);
        if (isIOS) {
          count++;
          await startCamera(null);
          return;
        } else {
          alert("No other camera available");
          return;
        }
      }
      deviceIndex = (deviceIndex + 1) % videoDevices.length;
      await startCamera(videoDevices[deviceIndex].deviceId || null);
    });

    resetDataBtn.addEventListener("click", () => {
      if (confirm("Are you sure you want to reset all attendance data? This cannot be undone.")) {
        localStorage.removeItem('attendanceRegistration');
        localStorage.removeItem('attendanceHistory');
        isRegistered = false;
        captureBtn.textContent = "Register Face";
        showAttendanceStatus("üìù Data reset. Please register your face first", "text-blue-600");
      }
    });

    captureBtn.addEventListener("click", async () => {
      if (!isModelsLoaded) {
        alert("AI models are still loading. Please wait...");
        return;
      }

      // Reset detector to SSD for new attempt
      currentFaceDetector = 'ssd';
      detectionRetryCount = 0;

      // Show loading state
      captureBtn.textContent = "Processing...";
      captureBtn.disabled = true;
      locationStatus.style.display = "block";
      locationStatus.textContent = "üîç Detecting face...";

      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

      try {
        // Use enhanced face detection with fallback
        const detection = await detectFaceWithFallback(canvas);

        if (!detection) {
          captureBtn.textContent = isRegistered ? "Mark Attendance" : "Register Face";
          captureBtn.disabled = false;
          locationStatus.style.display = "none";
          showAttendanceStatus("‚ùå No face detected with any detector. Please ensure your face is clearly visible and try again.", "text-red-600");
          return;
        }

        // Start liveness check instead of immediately proceeding
        locationStatus.textContent = "üëÅÔ∏è Starting liveness check...";
        startLivenessCheck();

        // Start continuous landmark detection for blink monitoring
        monitorBlinks(detection.descriptor);

      } catch (error) {
        console.error("Face detection error:", error);
        captureBtn.textContent = isRegistered ? "Mark Attendance" : "Register Face";
        captureBtn.disabled = false;
        locationStatus.style.display = "none";
        showAttendanceStatus("‚ùå Face detection failed", "text-red-600");
      }
    });

    // Monitor blinks continuously during liveness check
    async function monitorBlinks(faceDescriptor) {
      if (!isLivenessCheckActive) {
        return;
      }

      try {
        // Get current frame from video
        const tempCanvas = document.createElement('canvas');
        tempCanvas.width = video.videoWidth;
        tempCanvas.height = video.videoHeight;
        const tempCtx = tempCanvas.getContext('2d');
        tempCtx.drawImage(video, 0, 0, tempCanvas.width, tempCanvas.height);

        // Use current detector for landmark detection during monitoring
        const options = getFaceDetectorOptions();
        const detection = await faceapi
          .detectSingleFace(tempCanvas, options)
          .withFaceLandmarks();

        if (detection) {
          const blinkData = detectBlink(detection.landmarks);

          // Check if liveness is complete
          if (checkLivenessComplete()) {
            // Proceed with location and attendance processing
            await proceedWithAttendance(faceDescriptor);
            return;
          }
        } else {
          // If face lost during monitoring, show warning but continue
          if (isLivenessCheckActive) {
            showAttendanceStatus(`üëÅÔ∏è Face lost during monitoring. Please stay still. Blink ${blinkCount}/${REQUIRED_BLINKS}`, "text-orange-600");
          }
        }

        // Continue monitoring if still active
        if (isLivenessCheckActive) {
          setTimeout(() => monitorBlinks(faceDescriptor), 100); // Check every 100ms
        }

      } catch (error) {
        console.error("Blink monitoring error:", error);
        if (isLivenessCheckActive) {
          setTimeout(() => monitorBlinks(faceDescriptor), 100);
        }
      }
    }

    // Proceed with attendance after liveness check
    async function proceedWithAttendance(faceDescriptor) {
      locationStatus.textContent = "üåç Getting location...";

      // Get IP address with multiple fallback options
      let ipText = "IP: Unknown";
      try {
        // Try local server first (if running via server)
        const ipServices = [
          "/api/ip",  // Local server endpoint
          "https://api.ipify.org?format=json",
          "https://ipapi.co/json/",
          "https://api.my-ip.io/ip.json",
          "https://httpbin.org/ip",
          "https://api.bigdatacloud.net/data/client-ip"
        ];

        for (const service of ipServices) {
          try {
            const response = await fetch(service, {
              method: 'GET',
              timeout: 3000,
              headers: {
                'Accept': 'application/json'
              }
            });

            if (response.ok) {
              const data = await response.text();
              let ip = null;

              // Handle different response formats
              try {
                const jsonData = JSON.parse(data);
                ip = jsonData.ip || jsonData.origin || jsonData.ipAddress || jsonData.query;
              } catch {
                // If not JSON, treat as plain text
                ip = data.trim();
              }

              if (ip && (ip.match(/^\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}$/) || ip === '127.0.0.1')) {
                ipText = `IP: ${ip}`;
                break;
              }
            }
          } catch (serviceError) {
            console.warn(`Failed to get IP from ${service}:`, serviceError);
            continue;
          }
        }

        // If all services fail, try WebRTC method as last resort
        if (ipText === "IP: Unknown") {
          const rtcIp = await getLocalIP();
          if (rtcIp) {
            ipText = `Local IP: ${rtcIp}`;
          } else {
            // Final fallback - show browser and timestamp info instead
            const userAgent = navigator.userAgent;
            const browser = userAgent.includes('Chrome') ? 'Chrome' :
              userAgent.includes('Firefox') ? 'Firefox' :
                userAgent.includes('Safari') ? 'Safari' : 'Unknown';
            ipText = `Browser: ${browser} | No IP available`;
          }
        }

      } catch (e) {
        console.warn("Could not fetch IP from any service", e);
      }

      // Enhanced geolocation
      if ("geolocation" in navigator) {
        const options = {
          enableHighAccuracy: true,
          timeout: 10000,
          maximumAge: 60000
        };

        navigator.geolocation.getCurrentPosition(
          async (pos) => {
            try {
              const coords = pos.coords;
              const timestamp = new Date(pos.timestamp);
              const lat = coords.latitude;
              const lon = coords.longitude;
              const accuracy = coords.accuracy ? Math.round(coords.accuracy) : 'Unknown';

              if (!isRegistered) {
                // First time registration
                await registerUser(faceDescriptor, lat, lon, timestamp, ipText, accuracy);
              } else {
                // Attendance verification
                await verifyAttendance(faceDescriptor, lat, lon, timestamp, ipText, accuracy);
              }

            } catch (error) {
              console.error("Error processing:", error);
              captureBtn.textContent = isRegistered ? "Mark Attendance" : "Register Face";
              captureBtn.disabled = false;
              locationStatus.style.display = "none";
              showAttendanceStatus("‚ùå Error processing attendance", "text-red-600");
            }
          },
          (err) => {
            captureBtn.textContent = isRegistered ? "Mark Attendance" : "Register Face";
            captureBtn.disabled = false;
            locationStatus.style.display = "none";
            showAttendanceStatus("‚ùå Location access denied. Cannot process attendance.", "text-red-600");
          },
          options
        );
      } else {
        showAttendanceStatus("‚ùå Geolocation not supported", "text-red-600");
      }
    }

    async function registerUser(faceDescriptor, lat, lon, timestamp, ipText, accuracy) {
      locationStatus.textContent = "üíæ Registering user...";

      const registrationData = {
        faceDescriptor: Array.from(faceDescriptor),
        location: { lat, lon },
        timestamp: timestamp.toISOString(),
        ipAddress: ipText,
        accuracy: accuracy,
        livenessVerified: true,
        blinkCount: blinkCount,
        detectorUsed: currentFaceDetector.toUpperCase(),
        earThreshold: EAR_THRESHOLD
      };

      localStorage.setItem('attendanceRegistration', JSON.stringify(registrationData));

      // Draw registration info on canvas
      drawRegistrationInfo(lat, lon, timestamp, ipText, accuracy);

      isRegistered = true;
      captureBtn.textContent = "Mark Attendance";
      captureBtn.disabled = false;
      locationStatus.style.display = "none";
      showAttendanceStatus("‚úÖ Face registered with liveness verification! You can now mark attendance.", "text-green-600");

      // Show capture result
      showCaptureResult();
    }

    async function verifyAttendance(faceDescriptor, lat, lon, timestamp, ipText, accuracy) {
      locationStatus.textContent = "üîç Verifying identity...";

      const registrationData = JSON.parse(localStorage.getItem('attendanceRegistration'));
      const registeredDescriptor = new Float32Array(registrationData.faceDescriptor);

      // Calculate face similarity
      const distance = faceapi.euclideanDistance(faceDescriptor, registeredDescriptor);
      const isFaceMatch = distance < FACE_MATCH_THRESHOLD;

      locationStatus.textContent = "üìç Checking location...";

      // Calculate location distance
      const locationDistance = calculateDistance(
        lat, lon,
        registrationData.location.lat, registrationData.location.lon
      );
      const isLocationMatch = locationDistance <= LOCATION_MATCH_THRESHOLD;

      // Store attendance record
      const attendanceRecord = {
        timestamp: timestamp.toISOString(),
        location: { lat, lon },
        faceMatch: isFaceMatch,
        faceDistance: distance.toFixed(4),
        locationMatch: isLocationMatch,
        locationDistance: Math.round(locationDistance),
        ipAddress: ipText,
        accuracy: accuracy,
        livenessVerified: true,
        blinkCount: blinkCount,
        detectorUsed: currentFaceDetector.toUpperCase(),
        earThreshold: EAR_THRESHOLD,
        success: isFaceMatch && isLocationMatch
      };

      // Save to history
      let history = JSON.parse(localStorage.getItem('attendanceHistory') || '[]');
      history.push(attendanceRecord);
      localStorage.setItem('attendanceHistory', JSON.stringify(history));

      // Draw attendance result on canvas
      drawAttendanceResult(attendanceRecord, lat, lon, timestamp, ipText, accuracy);

      captureBtn.disabled = false;
      locationStatus.style.display = "none";

      if (attendanceRecord.success) {
        captureBtn.textContent = "Mark Attendance";
        showAttendanceStatus(`‚úÖ Attendance marked successfully! Face: ${(1 - distance).toFixed(2) * 100}% match, Location: ${Math.round(locationDistance)}m away`, "text-green-600");
      } else {
        captureBtn.textContent = "Mark Attendance";
        let errorMsg = "‚ùå Attendance failed: ";
        if (!isFaceMatch) errorMsg += `Face mismatch (${(distance * 100).toFixed(1)}% difference). `;
        if (!isLocationMatch) errorMsg += `Location too far (${Math.round(locationDistance)}m away).`;
        showAttendanceStatus(errorMsg, "text-red-600");
      }

      // Show capture result
      showCaptureResult();
    }

    function drawRegistrationInfo(lat, lon, timestamp, ipText, accuracy) {
      const texts = [
        "üéØ USER REGISTERED",
        `ÔøΩÔ∏è Liveness: VERIFIED (${blinkCount} blinks)`,
        `ÔøΩüìç Location: ${lat.toFixed(6)}, ${lon.toFixed(6)}`,
        `üìç Accuracy: ¬±${accuracy}m`,
        `üïê Time: ${timestamp.toLocaleString()}`,
        `üíª ${ipText}`,
        "‚úÖ Ready for attendance verification"
      ];

      drawInfoOnCanvas(texts, "rgba(0,128,0,0.8)");
    }

    function drawAttendanceResult(record, lat, lon, timestamp, ipText, accuracy) {
      const texts = [
        record.success ? "‚úÖ ATTENDANCE MARKED" : "‚ùå ATTENDANCE FAILED",
        `ÔøΩÔ∏è Liveness: VERIFIED (${blinkCount} blinks)`,
        `ÔøΩüë§ Face Match: ${record.faceMatch ? 'YES' : 'NO'} (${(1 - record.faceDistance) * 100}%)`,
        `üìç Location Match: ${record.locationMatch ? 'YES' : 'NO'} (${record.locationDistance}m)`,
        `üìç Current: ${lat.toFixed(6)}, ${lon.toFixed(6)}`,
        `üïê Time: ${timestamp.toLocaleString()}`,
        `üíª ${ipText}`
      ];

      const bgColor = record.success ? "rgba(0,128,0,0.8)" : "rgba(220,38,38,0.8)";
      drawInfoOnCanvas(texts, bgColor);
    }

    function drawInfoOnCanvas(texts, backgroundColor) {
      ctx.font = "16px Arial";
      ctx.fillStyle = "white";
      ctx.strokeStyle = "black";
      ctx.lineWidth = 2;

      const padding = 10;
      const lineHeight = 22;
      const textHeight = texts.length * lineHeight + padding * 2;
      const maxTextWidth = Math.max(...texts.map(text => ctx.measureText(text).width));

      // Draw background
      ctx.fillStyle = backgroundColor;
      ctx.fillRect(5, canvas.height - textHeight - 5, maxTextWidth + padding * 2, textHeight);

      // Draw text
      ctx.fillStyle = "white";
      texts.forEach((text, index) => {
        const y = canvas.height - textHeight + padding + (index + 1) * lineHeight;
        ctx.fillText(text, padding + 5, y);
      });
    }

    function showCaptureResult() {
      canvas.style.display = "block";
      downloadBtn.style.display = "inline-block";
      reCaptureBtn.style.display = "inline-block";
      video.style.display = "none";
      captureBtn.style.display = "none";
      stopCamera();
    }

    reCaptureBtn.addEventListener("click", () => {
      video.style.display = "block";
      captureBtn.style.display = "inline-block";
      canvas.style.display = "none";
      downloadBtn.style.display = "none";
      reCaptureBtn.style.display = "none";
      switchBtn.style.display = "inline-block";
      attendanceStatus.style.display = "none";
      (async () => {
        await getVideoDevices();
        await startCamera(videoDevices[deviceIndex]?.deviceId);
      })();
    });

    downloadBtn.addEventListener("click", () => {
      const link = document.createElement("a");
      const now = new Date();
      const timestamp = now.toISOString().replace(/[:.]/g, '-').slice(0, -5);
      const prefix = isRegistered ? 'attendance' : 'registration';
      link.download = `${prefix}-${timestamp}.png`;
      link.href = canvas.toDataURL("image/png");
      link.click();
    });

    // Initialize the application
    (async () => {
      await getVideoDevices();
      await startCamera(videoDevices[deviceIndex]?.deviceId);
      await loadModels();
    })();
  </script>
</body>

</html>